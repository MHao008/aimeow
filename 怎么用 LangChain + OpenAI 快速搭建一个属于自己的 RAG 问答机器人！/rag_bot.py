import os
from langchain_openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# ğŸ” è®¾ç½® OpenAI API Key
os.environ["OPENAI_API_KEY"] = "ä½ çš„OpenAI APIå¯†é’¥"
os.environ["OPENAI_API_BASE"] = "https://apikfm.com/v1" # è¿™é‡Œä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„APIï¼Œå¼€å‘å–µAPI 

# ğŸ“„ åŠ è½½ä½ çš„æœ¬åœ°æ–‡æ¡£
loader = TextLoader("test.txt", encoding='utf-8')
documents = loader.load()

# âœ‚ï¸ åˆ‡åˆ†æ–‡æ¡£ï¼ˆæ¯æ®µæœ€å¤š500å­—ç¬¦ï¼‰
text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)
docs = text_splitter.split_documents(documents)

# ğŸ” æ„å»ºå‘é‡ç´¢å¼•
embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_documents(docs, embeddings)

# ğŸ¤– æ„å»ºé—®ç­”é“¾
llm = ChatOpenAI(model_name="gpt-4o")  # ä¹Ÿå¯æ¢æˆ gpt-4
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever())

# ğŸ§ª å¼€å§‹å¯¹è¯
while True:
    query = input("ä½ æƒ³é—®ä»€ä¹ˆï¼Ÿï¼ˆè¾“å…¥ exit é€€å‡ºï¼‰ï¼š")
    if query.lower() == "exit":
        break
    result = qa_chain.run(query)
    print("ğŸ¤– AIå›ç­”ï¼š", result)