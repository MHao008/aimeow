import torch
from TTS.api import TTS

# from functools import partial

# # æ›¿æ¢ torch.loadï¼Œç¡®ä¿ weights_only=False
# torch_load_org = torch.load
# torch.load = partial(torch_load_org, weights_only=False)


# 1. æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU (NVIDIAæ˜¾å¡)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 2. å®šä¹‰æ¨¡å‹åç§°å’Œæ–‡ä»¶è·¯å¾„

# Â  Â XTTSv2æ˜¯é«˜è´¨é‡çš„å¤šè¯­è¨€å£°éŸ³å…‹éš†æ¨¡å‹

model_name ="tts_models/multilingual/multi-dataset/xtts_v2"

# Â  Â ä½ çš„å£°éŸ³æ ·æœ¬æ–‡ä»¶ï¼Œè¯·ç¡®ä¿å®ƒå’Œè„šæœ¬åœ¨åŒä¸€ç›®å½•ä¸‹

speaker_wav_path ="my.mp3" # <-- è¯·ä¿®æ”¹ä¸ºä½ çš„æ–‡ä»¶å



# Â  Â ä½ å¸Œæœ›AIç”¨ä½ çš„å£°éŸ³è¯´å‡ºçš„æ–‡æœ¬
text_to_clone ="è¿™æ˜¯ç”±äººå·¥æ™ºèƒ½å…‹éš†çš„æˆ‘ï¼Œå¦‚æœå–œæ¬¢æˆ‘ä»¬çš„è¯ï¼Œè¯·å…³æ³¨æˆ‘ä»¬ï¼Œæˆ‘ä»¬ä¼šæŒç»­æ›´æ–°æ–°çš„å†…å®¹ï¼Œå–œæ¬¢çš„è¯è¯·ç‚¹èµæ”¶è—è½¬å‘ï¼Œè°¢è°¢å¤§å®¶"


# Â  Â æœ€ç»ˆç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶ä¿å­˜è·¯å¾„
output_path ="cloned_voice_output.wav"

# 3. åˆå§‹åŒ–TTSæ¨¡å‹
#    ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ï¼Œç¨‹åºä¼šè‡ªåŠ¨ä»ç½‘ä¸Šä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼ˆçº¦2-3GBï¼‰
#    è¯·åŠ¡å¿…ä¿æŒç½‘ç»œé€šç•…ï¼Œå¹¶è€å¿ƒç­‰å¾…ï¼
print("æ­£åœ¨åŠ è½½TTSæ¨¡å‹ï¼Œé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œè¯·è€å¿ƒç­‰å¾…...")
tts = TTS(model_name, progress_bar=False).to(device)

# 4. æ‰§è¡Œå£°éŸ³å…‹éš†ï¼
print(f"\nå‡†å¤‡ä½¿ç”¨ '{speaker_wav_path}' çš„å£°éŸ³ï¼Œæœ—è¯»ä»¥ä¸‹æ–‡æœ¬ï¼š")
print(f"'{text_to_clone}'")
print("å¼€å§‹å…‹éš†ï¼Œè¯·ç¨å€™...")

#    è°ƒç”¨tts_to_fileæ–¹æ³•ï¼Œè¿™æ˜¯æœ€æ ¸å¿ƒçš„ä¸€æ­¥
#    text: è¦åˆæˆçš„æ–‡æœ¬
#    speaker_wav: ä½ çš„å£°éŸ³æ ·æœ¬æ–‡ä»¶è·¯å¾„
#    language: æ–‡æœ¬çš„è¯­è¨€ï¼ˆ'zh-cn'ä»£è¡¨ç®€ä½“ä¸­æ–‡ï¼‰
#    file_path: è¾“å‡ºéŸ³é¢‘çš„ä¿å­˜è·¯å¾„
tts.tts_to_file(
    text=text_to_clone,
    speaker_wav=speaker_wav_path,
    language="zh-cn",
    file_path=output_path
)
print(f"\nğŸ‰ å£°éŸ³å…‹éš†æˆåŠŸï¼éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_path}")
# å¯èƒ½å‡ºç°é”™è¯¯ï¼š   AttributeError: 'GPT2InferenceModel' object has no attribute 'generate'
# é™çº§ä¾èµ–å³å¯  python -m pip install transformers==4.33.0

